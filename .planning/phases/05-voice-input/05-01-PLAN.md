---
phase: 05-voice-input
plan: 01
type: execute
---

<objective>
Create audio capture infrastructure using sounddevice for recording voice input.

Purpose: Establish the foundational audio recording capability that PTT, VOX, and transcription will build upon.
Output: Audio module that can record from microphone to numpy buffer with start/stop control.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/arenamcp/server.py

**Prior phase context:**
- Phase 4 established FastMCP server pattern with lazy-loaded modules
- Module pattern: separate files in src/arenamcp/, imported in __init__.py

**Tech decisions:**
- sounddevice for audio capture (cross-platform, numpy integration)
- numpy for audio buffer management
- 16kHz sample rate (Whisper's native rate)
- Mono channel (voice doesn't need stereo)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add audio dependencies and create module skeleton</name>
  <files>pyproject.toml (or requirements.txt), src/arenamcp/audio.py</files>
  <action>
Add sounddevice and numpy to project dependencies.

Create src/arenamcp/audio.py with:
- AudioConfig dataclass: sample_rate=16000, channels=1, dtype='float32', device=None (default)
- AudioRecorder class skeleton with __init__(config: AudioConfig = None)

Use sounddevice.default.device to allow system default microphone. Don't hardcode device IDs.
  </action>
  <verify>python -c "from arenamcp.audio import AudioRecorder, AudioConfig; print('OK')"</verify>
  <done>Module imports successfully, AudioConfig and AudioRecorder classes exist</done>
</task>

<task type="auto">
  <name>Task 2: Implement recording buffer with start/stop API</name>
  <files>src/arenamcp/audio.py</files>
  <action>
Implement AudioRecorder methods:
- start_recording(): Begin capturing audio to internal buffer using sounddevice.InputStream with callback
- stop_recording() -> np.ndarray: Stop capture, return recorded audio as numpy array
- is_recording property: Check if currently recording
- _audio_callback(indata, frames, time, status): Append indata to buffer list

Internal state:
- _stream: Optional[sd.InputStream]
- _buffer: list of numpy arrays (append in callback, concatenate on stop)
- _recording: bool flag

Use threading.Lock to protect buffer access from callback thread.

Do NOT use blocking sd.rec() - we need non-blocking start/stop for PTT/VOX integration.
  </action>
  <verify>
python -c "
from arenamcp.audio import AudioRecorder
import time
r = AudioRecorder()
r.start_recording()
time.sleep(0.5)
audio = r.stop_recording()
print(f'Recorded {len(audio)} samples at {r.config.sample_rate}Hz = {len(audio)/r.config.sample_rate:.2f}s')
assert len(audio) > 0, 'No audio recorded'
print('OK')
"
  </verify>
  <done>AudioRecorder can start/stop recording, returns numpy array with captured audio</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from arenamcp.audio import AudioRecorder"` succeeds
- [ ] Recording test captures audio (non-zero samples)
- [ ] No blocking calls in recording flow
</verification>

<success_criteria>
- AudioRecorder class with start_recording/stop_recording API
- Non-blocking recording using InputStream callback
- Returns numpy array suitable for Whisper (16kHz float32 mono)
- Thread-safe buffer management
</success_criteria>

<output>
After completion, create `.planning/phases/05-voice-input/05-01-SUMMARY.md`
</output>
