---
phase: 07-coach-engine
plan: 01
type: execute
---

<objective>
Create a backend-agnostic Coach Engine supporting Claude, Gemini, and local LLMs (via Ollama).

Purpose: Enable intelligent coaching with flexibility to use cloud APIs or local models based on user preference.
Output: CoachEngine with pluggable LLM backends and GameStateTrigger for proactive advice detection.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Existing components to build on:**
@src/arenamcp/gamestate.py - GameState, TurnInfo with phase/step tracking
@src/arenamcp/server.py - get_game_state() serialization pattern, enrich_with_oracle_text()

**Voice I/O (for later integration):**
@src/arenamcp/voice.py - VoiceInput for user questions
@src/arenamcp/tts.py - VoiceOutput for speaking advice

**LLM Backend Options:**
1. Claude (Anthropic) - `anthropic` package (already installed)
2. Gemini (Google) - `google-generativeai` package
3. Local via Ollama - REST API at localhost:11434, `ollama` package optional

**Key patterns:**
- TurnInfo has: turn_number, active_player, priority_player, phase, step
- Phases: Phase_Beginning, Phase_Main1, Phase_Combat, Phase_Main2, Phase_Ending
- Steps: Step_Upkeep, Step_Draw, Step_DeclareAttackers, Step_DeclareBlockers, etc.

**Trigger conditions from roadmap:**
1. Priority pass - when we gain priority (decision point)
2. Combat - entering combat phase with attackers/blockers
3. New turn - start of each turn
4. Low life - player life falls below threshold
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLMBackend protocol and implementations</name>
  <files>src/arenamcp/coach.py</files>
  <action>
Create coach.py with abstract LLMBackend and concrete implementations:

1. LLMBackend Protocol (using typing.Protocol):
   - `complete(system_prompt: str, user_message: str) -> str`
   - Simple interface - takes system prompt + user message, returns response text

2. ClaudeBackend class:
   - Uses `anthropic.Anthropic()` client
   - Default model: "claude-sonnet-4-20250514"
   - Lazy client init (don't require API key until called)
   - Reads ANTHROPIC_API_KEY from env

3. GeminiBackend class:
   - Uses `google.generativeai` (import as genai)
   - Default model: "gemini-1.5-flash" (fast, good for real-time)
   - Lazy client init
   - Reads GOOGLE_API_KEY from env
   - Handle ImportError gracefully (package optional)

4. OllamaBackend class:
   - Uses HTTP requests to localhost:11434/api/generate
   - Default model: "llama3.2" (or configurable)
   - No API key needed (local)
   - Check if Ollama is running, clear error if not
   - Use requests library (already available)

5. Factory function:
   - `create_backend(backend_type: str, model: str = None) -> LLMBackend`
   - backend_type: "claude", "gemini", "ollama"
   - Returns configured backend instance

All backends should handle errors gracefully and return error message strings rather than raising exceptions (for resilient coaching).
  </action>
  <verify>
python -c "from arenamcp.coach import ClaudeBackend, GeminiBackend, OllamaBackend, create_backend; print('All backends importable')"
python -c "from arenamcp.coach import create_backend; b = create_backend('claude'); print(f'Created: {type(b).__name__}')"
  </verify>
  <done>
LLMBackend protocol defined. Claude, Gemini, Ollama implementations exist.
Factory function creates backends by name. All use lazy initialization.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create CoachEngine with context formatting</name>
  <files>src/arenamcp/coach.py</files>
  <action>
Add CoachEngine class that uses LLMBackend:

1. CoachEngine class:
   - `__init__(backend: LLMBackend = None, system_prompt: str = None)`
   - Default backend: ClaudeBackend() if none provided
   - Default system prompt: MTG coach persona (strategic, concise, spoken-friendly)
   - `_format_game_context(game_state_dict) -> str` - format for LLM context
   - `get_advice(game_state, question=None, trigger=None) -> str` - get coaching advice

2. System prompt design (for spoken output):
   - "You are an expert MTG coach providing real-time advice during Arena games."
   - "Keep responses concise (2-3 sentences) since they'll be spoken aloud."
   - "Focus on the most important strategic consideration."
   - "If asked a question, answer it directly. If triggered proactively, offer the key insight."

3. Context formatting (_format_game_context):
   - Life totals prominently at top
   - Turn number and phase
   - Whose priority (who can act)
   - Board state summary (creatures, key permanents)
   - Cards in hand with mana costs
   - Stack if not empty
   - Keep concise but complete enough for good advice

4. get_advice() logic:
   - Build user message from: context + (question OR trigger description)
   - If question: "The player asks: {question}"
   - If trigger: "Trigger: {trigger}. What should the player consider?"
   - Call backend.complete(system_prompt, user_message)
   - Return the advice text
  </action>
  <verify>
python -c "
from arenamcp.coach import CoachEngine, create_backend
# Test with mock game state (no actual API call without key)
engine = CoachEngine()
print(f'Engine created with backend: {type(engine._backend).__name__}')
# Test context formatting
mock_state = {
    'turn': {'turn_number': 5, 'phase': 'Phase_Main1', 'priority_player': 1},
    'players': [{'seat_id': 1, 'life_total': 18, 'is_local': True}, {'seat_id': 2, 'life_total': 12, 'is_local': False}],
    'hand': [{'name': 'Lightning Bolt', 'mana_cost': '{R}'}],
    'battlefield': [],
    'stack': [],
    'graveyard': [],
    'exile': []
}
ctx = engine._format_game_context(mock_state)
print(f'Context formatted ({len(ctx)} chars)')
assert 'Life' in ctx or 'life' in ctx
print('Context formatting works')
"
  </verify>
  <done>
CoachEngine accepts any LLMBackend. Context formatting produces readable game summary.
get_advice() handles both questions and triggers.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create GameStateTrigger and update exports</name>
  <files>src/arenamcp/coach.py, src/arenamcp/__init__.py</files>
  <action>
Add GameStateTrigger class to coach.py and update package exports:

1. GameStateTrigger class:
   - `__init__(life_threshold=5)` - configure trigger thresholds
   - `check_triggers(prev_state, curr_state) -> list[str]` - compare states, return trigger names

2. Trigger detection logic:
   - "new_turn": turn_number increased
   - "priority_gained": priority_player changed to local player
   - "combat_attackers": phase is Combat and step is DeclareAttackers, local is active
   - "combat_blockers": phase is Combat and step is DeclareBlockers, local is not active
   - "low_life": local player life dropped below threshold
   - "opponent_low_life": opponent life dropped below threshold (opportunity!)
   - "stack_spell": something was added to stack (response opportunity)

3. Helper to identify local player:
   - Check 'is_local' flag in players list
   - Handle missing data gracefully (return empty triggers)

4. Export in __init__.py:
   - Add: CoachEngine, GameStateTrigger, create_backend
   - Add: ClaudeBackend, GeminiBackend, OllamaBackend (for advanced users)
  </action>
  <verify>
python -c "from arenamcp import CoachEngine, GameStateTrigger, create_backend; print('Main exports work')"
python -c "from arenamcp.coach import ClaudeBackend, GeminiBackend, OllamaBackend; print('Backend exports work')"
python -c "
from arenamcp.coach import GameStateTrigger
t = GameStateTrigger()
# Test new turn trigger
prev = {'turn': {'turn_number': 1}, 'players': []}
curr = {'turn': {'turn_number': 2}, 'players': []}
triggers = t.check_triggers(prev, curr)
assert 'new_turn' in triggers, f'Expected new_turn, got {triggers}'
print(f'Triggers on new turn: {triggers}')

# Test low life trigger
prev = {'turn': {'turn_number': 2}, 'players': [{'seat_id': 1, 'life_total': 10, 'is_local': True}]}
curr = {'turn': {'turn_number': 2}, 'players': [{'seat_id': 1, 'life_total': 4, 'is_local': True}]}
triggers = t.check_triggers(prev, curr)
assert 'low_life' in triggers, f'Expected low_life, got {triggers}'
print(f'Triggers on low life: {triggers}')
print('All trigger tests pass')
"
  </verify>
  <done>
GameStateTrigger detects all trigger conditions.
All coach components exported from package.
Ready for Phase 8 MCP tools integration.
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "from arenamcp.coach import CoachEngine, GameStateTrigger, create_backend"` succeeds
- [ ] `python -c "from arenamcp.coach import ClaudeBackend, GeminiBackend, OllamaBackend"` succeeds
- [ ] `python -c "from arenamcp import CoachEngine, GameStateTrigger, create_backend"` succeeds
- [ ] create_backend("claude"), create_backend("gemini"), create_backend("ollama") all work
- [ ] CoachEngine context formatting produces readable game summary
- [ ] GameStateTrigger.check_triggers() detects: new_turn, priority_gained, combat_*, low_life
</verification>

<success_criteria>

- LLMBackend protocol with Claude, Gemini, Ollama implementations
- CoachEngine accepts any backend, formats context, returns advice
- GameStateTrigger detects all trigger conditions from roadmap
- Lazy initialization (no API keys required at import)
- Package exports updated
- Backend-agnostic design ready for user preference
</success_criteria>

<output>
After completion, create `.planning/phases/07-coach-engine/07-01-SUMMARY.md`:

# Phase 7 Plan 1: Coach Engine Summary

**[Substantive one-liner]**

## Accomplishments

- [Key outcomes]

## Files Created/Modified

- `src/arenamcp/coach.py` - LLMBackend protocol, Claude/Gemini/Ollama backends, CoachEngine, GameStateTrigger
- `src/arenamcp/__init__.py` - Updated exports

## Decisions Made

[Decisions and rationale]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 7 complete. Ready for Phase 8: MCP Voice Tools.
</output>
