---
phase: 06-voice-output
plan: 01
type: execute
---

<objective>
Integrate Kokoro TTS for speaking coach responses aloud.

Purpose: Enable the MTGA coach to speak advice audibly, completing the voice I/O loop.
Output: Working TTS module with playback via sounddevice, matching Phase 5's patterns.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Phase 5 patterns to follow:**
@src/arenamcp/transcription.py - WhisperTranscriber with lazy model loading
@src/arenamcp/voice.py - VoiceInput unified API

**Discovery findings (kokoro-onnx):**
- Install: `pip install kokoro-onnx`
- Model files: `kokoro-v1.0.onnx` (~300MB) + `voices-v1.0.bin` from GitHub releases
- API: `Kokoro.create(text, voice, speed, lang)` returns `(samples, sample_rate)`
- Sample rate: 24000 Hz fixed
- Best voice: `af_heart` (American English female, Grade A)
- Playback: `sd.play(samples, sample_rate); sd.wait()`

**Model file URLs:**
- https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/kokoro-v1.0.onnx
- https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/voices-v1.0.bin
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create KokoroTTS module with lazy model loading</name>
  <files>src/arenamcp/tts.py</files>
  <action>
Create tts.py following the WhisperTranscriber pattern from transcription.py:

1. KokoroTTS class with:
   - `__init__(model_path, voices_path, voice, speed, lang)` - configure but don't load
   - `_ensure_model_loaded()` - lazy load Kokoro instance on first use
   - `synthesize(text) -> tuple[np.ndarray, int]` - generate audio samples
   - Default voice: "af_heart" (highest quality American English)
   - Default speed: 1.0, lang: "en-us"

2. Model path handling:
   - Accept explicit paths or use default location (~/.cache/kokoro/)
   - Raise clear error if model files not found with download instructions

3. Thread-safe: Model loading should be thread-safe (use threading.Lock)

DO NOT download models automatically - just provide clear error message with URLs.
The model files are ~300MB total and should be downloaded manually once.
  </action>
  <verify>
python -c "from arenamcp.tts import KokoroTTS; t = KokoroTTS(); print('KokoroTTS imported')"
  </verify>
  <done>
KokoroTTS class exists with lazy loading pattern, synthesize() method defined, import succeeds.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create VoiceOutput class with sounddevice playback</name>
  <files>src/arenamcp/tts.py, src/arenamcp/__init__.py</files>
  <action>
Add VoiceOutput class to tts.py (unified output API, mirrors VoiceInput pattern):

1. VoiceOutput class with:
   - `__init__(voice, speed)` - configure TTS settings
   - `speak(text, blocking=True)` - synthesize and play audio
   - `speak_async(text)` - non-blocking playback, returns immediately
   - `stop()` - interrupt any ongoing playback
   - `is_speaking` property - check if audio is playing

2. Playback implementation:
   - Use sounddevice.play(samples, sample_rate) for blocking
   - For async: use sd.OutputStream with callback pattern
   - Handle PortAudioError gracefully (no audio device)

3. Export in __init__.py:
   - Add VoiceOutput and KokoroTTS to exports

Pattern note: VoiceOutput is the TTS counterpart to VoiceInput from voice.py.
Keep same lazy-loading and thread-safety patterns.
  </action>
  <verify>
python -c "from arenamcp import VoiceOutput; print('VoiceOutput exported')"
python -c "from arenamcp.tts import VoiceOutput, KokoroTTS; v = VoiceOutput(); print(f'VoiceOutput created, is_speaking={v.is_speaking}')"
  </verify>
  <done>
VoiceOutput class with speak(), speak_async(), stop(), is_speaking working.
Exported from arenamcp package. Playback ready (will fail gracefully without model files).
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "from arenamcp.tts import KokoroTTS, VoiceOutput"` succeeds
- [ ] `python -c "from arenamcp import VoiceOutput"` succeeds
- [ ] KokoroTTS follows lazy-loading pattern (no model load until synthesize called)
- [ ] VoiceOutput.speak() blocks until audio finishes
- [ ] VoiceOutput.is_speaking returns correct state
- [ ] Clear error message shown if model files missing
</verification>

<success_criteria>

- KokoroTTS module created with lazy loading matching WhisperTranscriber pattern
- VoiceOutput class provides speak()/speak_async()/stop() API
- Both classes are thread-safe
- Package exports updated
- No model download required for import (lazy loading)
- Clear error with download URLs if models missing at runtime
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-output/06-01-SUMMARY.md`:

# Phase 6 Plan 1: Voice Output Summary

**[Substantive one-liner]**

## Accomplishments

- [Key outcomes]

## Files Created/Modified

- `src/arenamcp/tts.py` - KokoroTTS and VoiceOutput classes
- `src/arenamcp/__init__.py` - Updated exports

## Decisions Made

[Decisions and rationale]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 6 complete. Ready for Phase 7: Coach Engine.
</output>
